---
layout:     post
title:      知识树：浅析SparkSQL & DataFrame
subtitle:   MSBD5003 阶段性知识总结
date:       2020-09-24
author:     Tex
header-img: img/post-bg-sparkLogo.png
catalog: true
tags:
    - 大数据分析 (Big Data Analytics)
    - 大数据计算 (Big Data Computing)
---

> DataFrame是Spark中另一实用数据类型，基于SparkSession；Spark选择在传统的数据文件交互(csv/json/etc)中使用这一数据类型，在Spark内部的计算中，DataFrame的计算最终会转为RDD的计算。

### DF与RDD显式转换

DF与RDD区别之一在于，在内部实现中RDD按行存储而DF按列存储，单就查询的需求，按列存储比按行存储效率要更高。

DF转RDD可以通过`.rdd`方法，而RDD转DF可以通过`.ToDF()`方法或`createDataFrame()`，实例如下，

```python
df = spark.read.csv('data/building.csv', header=True, inferSchema=True)
dfrdd = df.rdd
df_1 = dfrdd.toDF()
df_2 = spark.createDataFrame(dfrdd)
```

### DF的优化

RDD已经可以完成相同的功能了，为什么我们还需要DF呢？除了可读性更高，更灵活之外，最重要的一点叫做催化优化器(Catalyst Optimizer)。所谓的催化优化，个人简单理解为加速优化的意思，对比字面催化剂的含义，在化学实验中能使反应更快发生，所以在SQL计算中，能够使计算能够更快完成的优化。

![Plan Optimization](https://databricks.com/wp-content/uploads/2015/03/Screen-Shot-2015-03-23-at-3.59.28-PM.png)

SparkSQL中现有的优化绝大多数都是基于规则的 (Rule-based Optimization)，以树形转换为代表，会将各类计算的便捷计算方法编写为规则，常数折叠、谓语下推、空值传播、列剪枝、布尔表达式简化等。

可以参考如下实例。

![](/home/tian/Github/edwardtex.github.io/img/post-sql-1.png)

除此之外，SparkSQL中也有个别基于成本的优化 (CBO, Cost-based Optimization)，即上一章提及的[join()与broadcast](https://edwardtex.github.io/2020/09/16/SparkRDD/#broadcast%E5%8F%98%E9%87%8F%E9%97%AD%E5%8C%85%E4%B8%8Ejoin)，用于join()算法的选择优化，仅此而已。



### 回顾join()的各种姿势

可以通过如下一览表了解。在不加任何附加语句的情况下，join默认为inner join；而关于natural，可认为natural join与natural inner join等价，natural会删除表中的重复列；关于left join与left outer join，其实是完全相同的操作。

![sql join](https://www.runoob.com/wp-content/uploads/2019/01/sql-join.png)

### SparkSQL小贴士

- `filter`和`where`等价，完全可互换使用；

- 可以通过如下三种方式访问表下属性名，均合法；

  ```python
  dfProduct.select(dfProduct.ProductID, 'Name', (dfProduct['ListPrice'] * 2).alias('Double price'))
  ```

- 可以通过`createOrReplaceTempView()`方法给DF加表名，进而直接使用嵌入SQL查询；

  ```python
  df.createOrReplaceTempView('HVAC')
  spark.sql('SELECT * FROM HVAC WHERE BuildingAge >= 10').show()
  ```

- RDD中的闭包现象在DF中并不存在，请看实例：

  ```python
  x = 5
  df1 = df.filter(df._1 < x)
  df1.show()
  
  x = 3
  df1 = df.filter(df._1 < x)
  df1.show()
  ```

  输入如下，

  ```python
  +---+---+
  | _1| _2|
  +---+---+
  |  0|  0|
  |  1|  1|
  |  2|  2|
  |  3|  3|
  |  4|  4|
  +---+---+
  
  +---+---+
  | _1| _2|
  +---+---+
  |  0|  0|
  |  1|  1|
  |  2|  2|
  +---+---+
  ```

  这是由于之前提及的DF中的催化优化 (Catalyst Optimizer) 机制，DF中不必做额外的缓存操作。