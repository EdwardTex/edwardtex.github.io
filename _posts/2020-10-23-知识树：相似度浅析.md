---
layout:     post
title:      知识树：相似度浅析(Similarity Measure)
subtitle:   MSBD5001 阶段性知识总结
date:       2020-10-02
author:     Tex
header-img: img/post-bg-similarity.svg
catalog: true
tags:
    - 大数据分析 (Big Data Analytics)

---

> 

### 基本概念 - 相似度与距离

相似度(Similarity)是描述数据对象间相似程度的度量，与此对应的是差别度(Dissimilarity)，更常用的说法是距离(Distance)。在常见的数据对象中，类别、顺序数、比例数或区间的距离度量有不同的计算方式。

![](https://latex.codecogs.com/gif.latex?%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D%20Categorical%20%26%20%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D%20s%3D1%2C%5C%3Bif%5C%3Bx%3Dy%20%5C%5C%20s%3D0%2C%5C%3Bif%5C%3Bx%5Cneq%20y%20%5Cend%7Bmatrix%7D%5Cright.%20%26%20%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D%20d%3D0%2C%5C%3Bif%5C%3Bx%3Dy%5C%5C%20d%3D1%2C%5C%3Bif%5C%3Bx%5Cneq%20y%20%5Cend%7Bmatrix%7D%5Cright.%20%5C%5C%20Ordinal%20%26%20s%3D1-%5Cfrac%7B%5Cleft%20%5C%7C%20x-y%20%5Cright%20%5C%7C%7D%7Bn-1%7D%20%26%20d%3D%5Cfrac%7B%5Cleft%20%5C%7C%20x-y%20%5Cright%20%5C%7C%7D%7Bn-1%7D%5C%5C%20Ratio%28Interval%29%20%26%20%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D%20s%3D1-%5Cleft%20%5C%7C%20x-y%20%5Cright%20%5C%7C%5C%5C%20s%3D%5Cfrac%7B1%7D%7B1&plus;%5Cleft%20%5C%7C%20x-y%20%5Cright%20%5C%7C%7D%20%5Cend%7Bmatrix%7D%5Cright.%20%26%20d%3D%5Cleft%20%5C%7C%20x-y%20%5Cright%20%5C%7C%20%5Cend%7Bmatrix%7D%5Cright.)

除此之外，我们更多地涉及到字符串的处理。能否准确地度量字符串间的相似度，这是准确性(Accuracy)问题；以及如何面对大体量的相似度计算任务，这是可扩展性(Scalability)问题。

就准确性而言，有多种多样的问题： 笔误或者OCR错误；不同格式间转化；自定义的缩写简写略写等；字符串内部分元素的乱序等。找到能够合理处理上述问题的相似度度量方法是必要的。

就可扩展性而言，面对大体量任务，对每对字符串均进行计算意味着高额开销(O(n^2))，解决方法之一是先进行候选过滤，再基于候选集进行计算，这种方法称为FindCands。

相似度与距离这两个度量指标有通用的性质需要：对于相似度来说，归一化是必要的，1表示完全匹配，0表示完全不同，从0到1描述相似度；对于距离来说，要求反身性(Reflexive)，正值性(Positive)，对称性(Symmetric)以及满足三角不等式(Triangular inequation)。

沟通这两个度量指标有两种方式：

![](https://latex.codecogs.com/gif.latex?s%28x%2Cy%29%3D1-d%28x%2Cy%29%5C%3B%5C%3Bor%5C%3B%5C%3Bs%28x%2Cy%29%3D%5Cfrac%7B1%7D%7Bd%28x%2Cy%29%7D)

通过前者沟通，距离也具备归一化的性质；后者则是非线性的对应关系。

### 基于序列的相似度

基于序列，即将字符串看作单个字符顺序连接的相似度度量方法。

#### 汉明距离(Hamming Distance)

该方法要求两个字符串长度相同，通过对应位置不同元素的个数作为距离值。常见于二进制序列的通信误差度量。简单举例如下。

![](https://latex.codecogs.com/gif.latex?d%28%60%60peter%22%2C%20%60%60pedro%22%29%20%3D%203)

#### 编辑距离(Edit Distance / Levenshtein Distance)

编辑距离通过衡量从一字符串变成另一字符串所需要的最少花费(cost)，花费依此定义：删除、插入、替换均损耗1费。如何确定最少花费，我们需要借助动态规划。

在写出状态转移方程之前，我们首先要把状态定义完备：

![](https://latex.codecogs.com/gif.latex?%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D%20d%28i%2Cj%29%3Athe%5C%3Bdistance%5C%3Bbetween%5C%3Bi_%7Bth%7D%5C%3Belement%5C%3Band%5C%3Bj_%7Bth%7D%5C%3Belement%20%5C%5C%20d%28i%2C0%29%3Di%20%5C%5C%20d%280%2Cj%29%3Dj%20%5Cend%7Bmatrix%7D%5Cright.)

假设两条字符串的长度分别为n和m，那么我们的状态空间为一个(n+1)By(m+1)的矩阵；进而我们依据编辑距离的定义，给出状态转移方程，

![](https://latex.codecogs.com/gif.latex?d%28i%2Cj%29%3Dmin%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D%20d%28i-1%2Cj%29&plus;1%20%26%20%5C%5C%20d%28i%2Cj-1%29&plus;1%20%26%20%5C%5C%20d%28i-1%2Cj-1%29&plus;1%2C%20%26%20if%5C%3Bx_i%20%5Cneq%20y_j%20%5C%5C%20d%28i-1%2Cj-1%29%2C%20%26%20if%5C%3Bx_i%3Dy_i%20%5Cend%7Bmatrix%7D%5Cright.)

在状态空间组成的矩阵中，状态的转移意味着将矩阵中每个位置填上正确的元素，基于最终得到的距离d(m,n)我们可以找到该状态的回溯路径。根据路径我们可以得到将字符串x转化为字符串y所需的操作，即，

*路径方向为横向时，代表插入元素；为纵向时，代表删除元素；为斜向时，若状态转移前后发生变化，代表替换元素，若状态转移前后相同，代表元素相同，无操作。*

编辑距离对应的相似度度量定义如下，

![](https://latex.codecogs.com/gif.latex?s%28x%2Cy%29%3D1-%5Cfrac%7Bd%28x%2Cy%29%7D%7Bmax%28len%28x%29%2Clen%28y%29%29%7D)

#### Needleman-Wunch度量

这是一种基于编辑距离的泛化方法。通过定义对齐符号和分数，最终返回有最高分的对齐格式(alignment)。具体来说，我们通过定义分数矩阵作为状态空间，并引入**间隔惩罚分(Gap Penalty)**。与编辑距离不同，N-W度量采用的分数是相似度的正相关度量，字符相同记2分，不同记-1分。因此对齐格式的分数计算法如下，

![](https://latex.codecogs.com/gif.latex?Denote%5C%3Bthat%5C%3B%20%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D%20S_a%2C%26%20Score%5C%3Bof%5C%3Bthe%5C%3Balignment%20%5C%5C%20n_s%2C%26%20Number%5C%3Bof%5C%3Bsame%5C%3Belements%5C%5C%20n_d%2C%26%20Number%5C%3Bof%5C%3Bdifferent%5C%3Belements%5C%5C%20C_g%2C%26%20Gap%5C%3Bpenalty%20%5C%5C%20n_g%2C%26%20Number%5C%3Bof%5C%3Bgaps%20%5Cend%7Bmatrix%7D%5Cright.)

![](https://latex.codecogs.com/gif.latex?S_a%3D2n_s-n_d-C_g*n_g)

 与编辑距离相同，我们需要借助动态规划进行求解，状态定义如下，
 
 ![](https://latex.codecogs.com/gif.latex?%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D%20s%28i%2Cj%29%3Athe%5C%3Bscore%5C%3Bof%5C%3Bi_%7Bth%7D%5C%3Belement%5C%3Band%5C%3Bj_%7Bth%7D%5C%3Belement%20%5C%5C%20s%28i%2C0%29%3D-i*C_g%20%5C%5C%20s%280%2Cj%29%3D-j*C_g%20%5Cend%7Bmatrix%7D%5Cright.)
 
 假设两条字符串的长度分别为n和m，那么我们的状态空间为一个(n+1)By(m+1)的分数矩阵；进而我们得到状态转移方程，
 
 ![](https://latex.codecogs.com/gif.latex?s%28i%2Cj%29%3Dmax%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D%20s%28i-1%2Cj%29-C_g%5C%5C%20s%28i%2Cj-1%29-C_g%5C%5C%20s%28i-1%2Cj-1%29&plus;c%28x_%7Bi%7D%2Cy_%7Bj%7D%29%20%5Cend%7Bmatrix%7D%5Cright.)

其中的映射c表示上面提到的分数，字符相同记2分，不同记-1分。

与编辑距离相同，基于最终得到的分数s(m,n)我们可以找到该状态的回溯路径。根据路径我们可以得到将字符串x转化为字符串y所需的操作，即，

*路径方向为横向时，代表插入间隔(Gap)；为纵向时代表删除元素；为斜向时，若状态转移前后分数差为2分，代表元素相同，无操作，若状态转移前后分数差为1分，代表替换元素。*

#### 仿射间隔度量(Affine Gap Measure)

N-W度量虽然引入了间隔操作，但是是有缺陷的，当所需间隔过长时，比如中间名的情况，过长的间隔会导致本该判别为高相似度的字符串对，因此被砍掉高额的间隔惩罚分。

针对这种缺陷，引入了仿射间隔的概念。仿射间隔将间隔的计算方式进行了改进，将间隔惩罚分区分为创建间隔分和继续间隔分，因此新的间隔惩罚分计算如下，

![](https://latex.codecogs.com/gif.latex?Denote%5C%3Bthat%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D%20C_g%28k%29%20%26%20The%5C%3Bgap%5C%3Bpenalty%5C%3Bof%5C%3Ba%5C%3Bgap%5C%3Bwith%5C%3Bsize%5C%3Bof%5C%3Bk%5C%5C%20C_o%20%26%20The%5C%3Bgap%5C%3Bpenalty%5C%3Bof%5C%3Bopening%5C%3Ba%5C%3Bgap%5C%5C%20C_r%20%26%20The%5C%3Bgap%5C%3Bpenalty%5C%3Bof%5C%3Bcontinuing%5C%3Ba%5C%3Bgap%20%5Cend%7Bmatrix%7D%5Cright.)

![](https://latex.codecogs.com/gif.latex?C_g%28k%29%3DC_o&plus;%28k-1%29C_r%2C%5C%3B%5C%3Bwhere%5C%3BC_r%3CC_o)

在引入仿射间隔之后，状态不再由单一的分数构成，而是如下更为复杂的情况，

![]()

同样的，在写出状态转移方程之前，我们需要将状态空间定义完备，

![]()

状态转移方程如下，

![]()

仿射间隔度量的回溯路径与转换操作的对应规则为，*路径方向为横向时，代表插入间隔(Gap)；为纵向时代表删除元素；为斜向时，若状态转移前后分数差为2分，代表元素相同，无操作，若状态转移前后分数差为1分，代表替换元素。*

#### Smith-Waterman度量

S-W度量同样是N-W度量的一种泛化方法，N-W度量采用的是全局匹配的策略，这在某些实例中会出问题，比如包含作者姓名的头衔单位字符串与作者姓名字符串的匹配，多出的头衔单位等字符会拉低N-W度量的相似度分数。

S-W度量的核心在于采用局部匹配的策略，允许从字符串的任意位置开始重新匹配，并且允许在非最优匹配的情况下忽略字符串的后缀。通过这种策略，突出字符串中我们想要的子字符串。

状态空间定义如下，

![]()

状态转移方程定义如下，

![]()

S-W度量的回溯路径与转换操作的对应规则与N-W度量基本相同，因为采取局部匹配的策略，在子字符串相似度极高的情况下，前缀后缀允许被直接抛弃。

#### Jaro度量

这是一种主要用于匹配短字符串的度量算法，例如姓名。该度量方法从相同字符的数量入手，通过相同子字符串在待匹配字符串中的占比，以及对所需移位操作的考量，得到了如下相似度分数计算方法，

![]()

#### Jaro-Winkler度量

J-W度量在Jaro度量的基础上，加入了对共用前缀的特别捕捉，相似度分数计算方法如下，

![]()



### 基于集合的相似度

基于集合，即将字符串看作词组(token)的集合的度量方法。

从字符串中生成词组有两大类方法：第一类是由空格划界的方法，有必要时需要再对单词做分割，以及去掉无意义的停止词(stop words)；第二类是Q-gram方法，使用#来标识字符串的起止。

当我们拿到从字符串中生成的词组后，我们来考虑相似度的问题。

#### Overlap度量

该度量方法返回两个词组集合交集内元素的数量，即，

![]()

以2-gram方法举例如下，

![]()

#### Jaccard度量

该度量方法返回两个词组集合交集与并集元素数量之比，即，

![]()

在上例中，Jaccard度量返回为，

![]()

#### TF/IDF度量

Term Frequency/Inverse Document Frequency，这是非常流行的相似度度量方法之一，这种方法可以根据更具辨识度的词组来判别相似度。其中，

![]()

![]()

进而，每个term都有特征向量来标识，从而计算相似度分数，

![]()

当相似度分数很高时，说明待匹配的两个字符串有许多相同的高频词，即TF分数高的词组。在实际应用中，TF/IDF阻尼化和特征向量的归一化都是基本操作。

![]()

![]()

### 混合相似度度量

#### 泛化Jaccard度量

Jaccard度量在某些实例中会过于严格，在面对一些typo的情况时不够灵活。

![]()


#### Soft TF/IDF度量

![]()

#### Monge-Elkan度量

![]()


#### Soundex度量


### 可扩展性

同上所述，就可扩展性而言，面对大体量任务，解决方法之一是先进行候选过滤，再基于候选集进行计算，这种方法称为FindCands。

#### 倒转索引(Inverted Index)

统计集合X中元素在集合Y中的词(token)-文件(document)归属关系，其中的文件是指经过原字符串分词后得到的集合。从而集合X中进行每个文件的匹配时，都可以依据归属关系找到仅包含该文件的子集Z，从而完成候选过滤。

在实际应用中，该方法有明显缺陷，首先是某些词组的倒转索引列表会很长，比如停止词；其次尽管通过这样的候选过滤得到的子集Z，空间可能依然很大；在这样的候选结果上直接操刀，成本依旧很高。

#### 尺寸过滤(Size Filtering)

在候选过滤的过程中增加尺寸约束t，再通过B-Tree索引进行检索满足约束t的结果。

#### 前缀过滤(Prefix Filtering)

如果集合X和Y的交集空间过大，即有太多相同词组的情况下，倒转索引得到的子集空间依然很大，在候选过滤的过程中增加前缀长度约束，再通过倒转索引进行检索满足前缀约束的结果。

### 相似度度量实际应用包

- Python-Levenshtein [https://pypi.python.org/pypi/python-Levenshtein](https://pypi.python.org/pypi/python-Levenshtein) 

- NLTK [http://www.nltk.org/](http://www.nltk.org/)

- FuzzyWuzzy [https://pypi.python.org/pypi/fuzzywuzzy](https://pypi.python.org/pypi/fuzzywuzzy)

- Harry [http://www.mlsec.org/harry/tutorial.html](http://www.mlsec.org/harry/tutorial.html)

- SecondString [http://secondstring.sourceforge.net/](http://secondstring.sourceforge.net/)

- SimMetrics [https://sourceforge.net/projects/simmetrics/](https://sourceforge.net/projects/simmetrics/)


